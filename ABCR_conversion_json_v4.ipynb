{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of this python script is to be able to implement ABCR berths to each terminus station in the line.\n",
    "\n",
    "Unfortunately, I couldn't find any pattern all of the terminus platforms in each respective line so that the code could do it \n",
    "all automatically. However, it is not very tedious to find all of these terminus platforms using opentraintimes. Once you locate\n",
    "a terminus you can go to the INPUTS section and put the required inputs for the following functions to work so that you can add\n",
    "the berth to that given platform. You will have to do this for every terminus platform you find in the line.\n",
    "\n",
    "After running all the functions, the original JSON file will have bnew ABCR berths signals included in each terminus stations\n",
    "with links in between them. Moreover, all of the inputs can be obtained through the DRIVE which makes the process more efficient.\n",
    "\n",
    "Once you open the file again, in order to have pretty printing press SHIFT+Alt+F in Visual Studio.\n",
    "\n",
    "Finally, a recommendation is to save a coy of the JSON tracks file on another folder in case something doesn't work as planned\n",
    "as these functions will rewrite the original JSON file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silencing_links(path: \"json\",x1: \"float\",x2: \"float\",y1: \"float\",y2: \"float\"):\n",
    "    \"\"\"\n",
    "    The purpose of this function will be to silence all of the links of the nodes/signals between x1 and x2 as you will later\n",
    "    see that it is easier to create new links in between all of them once the ABCR berths are added. Therefore, this function\n",
    "    adds a _D at the end of the id, source and target in each link.\n",
    "    \n",
    "    path : Path of the JSON file in the computer. Don't forget to add an r before it as seen in the examples below.\n",
    "    \n",
    "    x1 : The x coordinate most to the left of the given range for x coordinates, if terminus signal going to right, then x1\n",
    "    is the same as the coordinate of the terminus signal.\n",
    "    \n",
    "    x2 : The x coordinate most to the right of the given range for x coordinates, if terminus signal going to left, then x2\n",
    "    is the same as the coordinate of the terminus signal.\n",
    "    \n",
    "    y1 : The bottom y coordinate in the y range.\n",
    "    \n",
    "    y2 : The upper y coordinate in the y range.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path) as data_file:    \n",
    "        data = json.load(data_file) \n",
    "    #This open the JSON file and the following line creates a dataframe of the 'nodes' in the JSON file.\n",
    "    df_nodes = pd.DataFrame(data['nodes'])\n",
    "    #The df_nodes is tranformed into a zipped list for having easier operations.\n",
    "    list_nodes = list(zip(df_nodes['id'],df_nodes['x'],df_nodes['y'],df_nodes['name'],df_nodes['direction']))\n",
    "    #The following empty list_new_nodes will be a list which will only include nodes that are in the given x and y range\n",
    "    #after the for loop is run.\n",
    "    list_new_nodes = []\n",
    "    for i in list_nodes:\n",
    "        if  (x1 < i[1] < x2 + 2) and ( y1 - 2 < i[2] < y2 + 2):\n",
    "            list_new_nodes.append(i)\n",
    "    df_links = pd.DataFrame(data['links'])\n",
    "    #This will be a dataframe of the links in the JSON file and list_links its respective zipped list.\n",
    "    list_links = list(zip(df_links['id'],df_links['source'],df_links['target']))   \n",
    "    #list_new_links will be the list of all the links associated with the nodes from list_new_nodes in the x-y ranges.\n",
    "    list_new_links = []\n",
    "\n",
    "    for i in list_new_nodes:\n",
    "        for b in list_links:\n",
    "            if i[0] == (b[1] or b[2]):\n",
    "                #i[0] is the id of the node which can apear either in the source or target of the link. This leads to the\n",
    "                #addition of repeated links as the same link will be added twice once i[0] is the source and later when\n",
    "                #it is the target.\n",
    "                list_new_links.append(b)\n",
    "    list_new_links = list(set(list_new_links))\n",
    "    #Use of set function to get rid of repeated links.\n",
    "    list_updated_links = []\n",
    "    #This function will contain the updated links with most of them as they were initially except the ones in the x-y range,\n",
    "    #which will have a _D at the end.\n",
    "    for i in list_links:\n",
    "        x = False\n",
    "        for b in list_new_links:\n",
    "            if (i[1] == b[1]) and (i[2] == b[2]):\n",
    "                #if the same links are in list_links and list_new_links, then the _D is added to these links and these new\n",
    "                #links are added to list_updated_links.\n",
    "                new_id = i[0] +\"_D\"\n",
    "                new_source = i[1] + \"_D\"\n",
    "                new_target = i[2] + \"_D\"\n",
    "                new_link = (new_id,new_source,new_target)\n",
    "                list_updated_links.append(new_link)\n",
    "                x = True\n",
    "        if x == False:\n",
    "            #Otherwise, if the links don't appear is list_new_links then they are just added to list_updated_links.\n",
    "            list_updated_links.append(i)\n",
    "\n",
    "    Id = []\n",
    "    source = []\n",
    "    target = []\n",
    "    for i in list_updated_links:\n",
    "        Id.append(i[0])\n",
    "        source.append(i[1])\n",
    "        target.append(i[2])\n",
    "    df_update_links = pd.DataFrame(columns= ['id','source','target'])\n",
    "    df_update_links['id'] = Id\n",
    "    df_update_links['source'] = source\n",
    "    df_update_links['target'] = target\n",
    "    #After creating a new dataframe, this is converted to json format and then loaded as a json string which replaces the \n",
    "    #map links in the original JSON file. The last two lines rewrite the JSON file and the links in the x-y range are now\n",
    "    #silenced.\n",
    "    df_update_links_json = df_update_links.to_json(orient = 'records')\n",
    "    json_object = json.loads(df_update_links_json)\n",
    "    data['links'] = json_object\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_abcr(path,plat_id,signal_id,direction):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to add ABCR berth signals in the nodes map in the JSON file which will either go to the\n",
    "    right or left of the given terminus signal in the terminus platform.\n",
    "    \n",
    "    path : Path of the JSON file in the computer. Don't forget to add an r before it as seen in the examples below.\n",
    "    \n",
    "    plat_id : ID of the terminus platform to which you want to add the ABCR berths.\n",
    "    \n",
    "    signal_id : ID of the terminus signal in the terminus platform.\n",
    "    \n",
    "    direction : either 'r' or 'l' (or whatever). 'r' will mean that the ABCR starting from A will go to the right of the \n",
    "    terminus signal. Otherwise, it will go to the left.\n",
    "    \n",
    "    Finally, the code will rewrite the 'nodes' map in the JSON file including the new berths.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path) as data_file:    \n",
    "        data = json.load(data_file) \n",
    "    #This opens the JSON file and then df_nodes and df_platforms are the respective dataframes of the 'nodes' and 'platforms'\n",
    "    #as well as their respective zipped list. \n",
    "    df_nodes = pd.DataFrame(data['nodes'])\n",
    "    list_nodes = list(zip(df_nodes['id'],df_nodes['x'],df_nodes['y'],df_nodes['name'],df_nodes['direction']))\n",
    "    df_platforms = pd.DataFrame(data['platforms'])\n",
    "    list_platforms = list(zip(df_platforms['id'],df_platforms['x1'],df_platforms['x2'],df_platforms['y1'],df_platforms['y2']))\n",
    "    signal = 0\n",
    "    for i in list_nodes:\n",
    "        if i[0] == signal_id:\n",
    "            signal = i\n",
    "    platform = 0\n",
    "    for i in list_platforms:\n",
    "        if i[0] == plat_id:\n",
    "            platform = i\n",
    "    #After this for loops we have the signal and platform with the same ID's as in the inputs.\n",
    "    integers = \"0123456789\"\n",
    "    new_name = \"\"\n",
    "    for i in signal[3]:\n",
    "        if i in integers:\n",
    "            new_name += i\n",
    "    #This for loop is used so that only the number part in the signal ID is included after the A/B/C/R of the berth.\n",
    "    #e.g. SN: 356 -> A356,B536,C356,D356.\n",
    "    dx = (abs(platform[2] - platform[1]))/4\n",
    "    #dx is ths difference between x1 and x2 in the platforms divided by 4.\n",
    "    list_berths = [\"A\",\"B\",\"C\",\"R\"]\n",
    "    for i in range(len(list_berths)):\n",
    "        Id =  \"v\" + str(i+1) + \"_\" + signal[0]\n",
    "        #The id's of each berth will have a vi_ as a prefix for the id of the terminus signal, where i is an integer from 1\n",
    "        #to 4.\n",
    "        if direction == \"r\":\n",
    "            x = signal[1] + (i+1)*dx\n",
    "            #the x coordinate of each berth will be to the right of the terminus signal.\n",
    "        else:\n",
    "            #the x coordinate of each berth will be to the left of the terminus signal.\n",
    "            x = signal[1] - (i+1)*dx\n",
    "        y = signal[2]\n",
    "        #the berths will have the same y coordinates.\n",
    "        name = list_berths[i] + new_name\n",
    "        #The name of the berths will be their respective letter and then the number in the name the signal.\n",
    "        direction_nodes = signal[4]\n",
    "        berth = (Id,x,y,name,direction_nodes)\n",
    "        list_nodes.append(berth)\n",
    "        #Appends the berths to the original list_nodes.\n",
    "    Id_nodes = []\n",
    "    x = []\n",
    "    y = []\n",
    "    name = []\n",
    "    direction_nodes = []\n",
    "    for i in list_nodes:\n",
    "        Id_nodes.append(i[0])\n",
    "        x.append(i[1])\n",
    "        y.append(i[2])\n",
    "        name.append(i[3])\n",
    "        direction_nodes.append(i[4])\n",
    "    df_update_nodes = pd.DataFrame(columns= ['id','x','y','name','direction'])\n",
    "    df_update_nodes['id'] = Id_nodes\n",
    "    df_update_nodes['x'] = x\n",
    "    df_update_nodes['y'] = y\n",
    "    df_update_nodes['name'] = name\n",
    "    df_update_nodes['direction'] = direction_nodes\n",
    "    df_update_nodes_json = df_update_nodes.to_json(orient = 'records')\n",
    "    json_object = json.loads(df_update_nodes_json)\n",
    "    data['nodes'] = json_object\n",
    "    #The previous lines just create a new dataframe will the new berths included and then rewrites the 'nodes' map in the \n",
    "    #original JSON file.\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(data, json_file)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_links(path,x1,x2,y1,y2,link_id,direction):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to create links in between all the nodes/signals and berths in a given x-y range, the\n",
    "    same x-y range given for the silencing_links() function.\n",
    "    \n",
    "    path : Path of the JSON file in the computer. Don't forget to add an r before it as seen in the examples below.\n",
    "    \n",
    "    x1 : The x coordinate most to the left of the given range for x coordinates, if terminus signal going to right, then x1\n",
    "    is the same as the coordinate of the terminus signal.\n",
    "    \n",
    "    x2 : The x coordinate most to the right of the given range for x coordinates, if terminus signal going to left, then x2\n",
    "    is the same as the coordinate of the terminus signal.\n",
    "    \n",
    "    y1 : The bottom y coordinate in the y range.\n",
    "    \n",
    "    y2 : The upper y coordinate in the y range.\n",
    "    \n",
    "    link_id : The id of any link connected to the terminus signal.\n",
    "    \n",
    "    direction : either 'r' or 'l' (or whatever). 'r' will mean that the ABCR starting from A will go to the right of the \n",
    "    terminus signal. Otherwise, it will go to the left. Consequently, all links will go from either right to left or viceversa.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "    #This opens the JSON file and then df_nodes and df_links are the respective dataframes of the 'nodes' and 'links'\n",
    "    #as well as their respective zipped list.\n",
    "    df_nodes = pd.DataFrame(data['nodes'])\n",
    "    list_nodes = list(zip(df_nodes['id'],df_nodes['x'],df_nodes['y'],df_nodes['name'],df_nodes['direction']))\n",
    "    df_links = pd.DataFrame(data['links'])\n",
    "    list_links = list(zip(df_links['id'],df_links['source'],df_links['target']))\n",
    "    #list_new_nodes is the list that will contain all the nodes in the given x-y range.\n",
    "    list_new_nodes = []\n",
    "    for i in list_nodes:\n",
    "        if  (x1 - 1 < i[1] < x2 + 2 ) and ( y1 - 2 < i[2] < y2 + 2):\n",
    "            list_new_nodes.append(i)\n",
    "    #As direction is going to the right, all nodes and berths in list_new_nodes are ordered from smallest to largest x coordinate\n",
    "    #so that the first node is the one most to the left and the final one most to the right.\n",
    "    if direction == \"r\":\n",
    "        list_new_nodes = sorted(list_new_nodes, key=lambda tup: tup[1])\n",
    "    #Otherwise, it will be sorted from the biggest (right) x coordinate to the smaless (left)\n",
    "    else:\n",
    "        list_new_nodes = sorted(list_new_nodes, key=lambda tup: tup[1], reverse=True)\n",
    "    #This for loop will be the one creating the links, as it uses the indexes of the nodes in list_new_nodes, it was necessary to\n",
    "    #sort them out in terms of their x coordinates as they were before randomly distributed in list_new_nodes which could lead\n",
    "    #to the wrong links being created.\n",
    "    for i in range(len(list_new_nodes)):\n",
    "        if i == len(list_new_nodes) -1:\n",
    "            break\n",
    "        else: \n",
    "            Id = \"v\" + str(1+i) + \"_\" + link_id\n",
    "            source = list_new_nodes[i][0]\n",
    "            target = list_new_nodes[i+1][0]\n",
    "            new_link = (Id,source,target)\n",
    "            list_links.append(new_link)\n",
    "    Id = []\n",
    "    source = []\n",
    "    target = []\n",
    "    for i in list_links:\n",
    "        Id.append(i[0])\n",
    "        source.append(i[1])\n",
    "        target.append(i[2])\n",
    "    df_update_links = pd.DataFrame(columns= ['id','source','target'])\n",
    "    df_update_links['id'] = Id\n",
    "    df_update_links['source'] = source\n",
    "    df_update_links['target'] = target\n",
    "    df_update_links_json = df_update_links.to_json(orient = 'records')\n",
    "    json_object = json.loads(df_update_links_json)\n",
    "    data['links'] = json_object\n",
    "    #The previous lines just create a new dataframe will the new berths included and then rewrites the 'links' map in the \n",
    "    #original JSON file.\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(data, json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                                                        INPUTS\n",
    "                                                \n",
    "\"\"\"\n",
    "\n",
    "path = r'C:\\Users\\Gyalpo\\Documents\\Cogitare\\drive\\assets\\data\\ds\\lner-tracks.json'\n",
    "#Either the x1 or x2 will be the coordinate from the terminus signal. The other x coordinate should be an x coordinate a bit far\n",
    "#from the end of the platform in the repsective direction.\n",
    "x1 = -271416.8       \n",
    "x2 = -268395.8 \n",
    "y1 = 120606\n",
    "y2= 120608\n",
    "plat_id = \"HTRWTM5_P4\"\n",
    "signal_id = \"71_gw180\"\n",
    "link_id = \"P103_gw180\"\n",
    "direction = \"l\"\n",
    "\n",
    "\"\"\"\n",
    "Try to run ech function at once and make sure each of them does what they are supposed to do to make sure you are putting the \n",
    "right inputs. Moreover, it is recommendable to save a copy in case something goes wrong as this will rewrite the whole file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "silencing_links(path,x1,x2,y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "creating_abcr(path,plat_id,signal_id,direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "creating_links(path,x1,x2,y1,y2,link_id,direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
